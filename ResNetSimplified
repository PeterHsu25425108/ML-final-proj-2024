{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bbdf798",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-06-17T10:10:09.982792Z",
     "iopub.status.busy": "2024-06-17T10:10:09.982462Z",
     "iopub.status.idle": "2024-06-17T10:10:15.530594Z",
     "shell.execute_reply": "2024-06-17T10:10:15.529863Z"
    },
    "papermill": {
     "duration": 5.556226,
     "end_time": "2024-06-17T10:10:15.532812",
     "exception": false,
     "start_time": "2024-06-17T10:10:09.976586",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "# use process bar tool\n",
    "from tqdm import tqdm\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import DataLoader, Subset,Dataset\n",
    "# use process bar tool\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "import os\n",
    "#for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#    for filename in filenames:\n",
    "#        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0a895e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T09:14:44.268049Z",
     "iopub.status.busy": "2024-06-17T09:14:44.267583Z",
     "iopub.status.idle": "2024-06-17T09:14:44.276415Z",
     "shell.execute_reply": "2024-06-17T09:14:44.275405Z",
     "shell.execute_reply.started": "2024-06-17T09:14:44.268019Z"
    },
    "papermill": {
     "duration": 0.004337,
     "end_time": "2024-06-17T10:10:15.542130",
     "exception": false,
     "start_time": "2024-06-17T10:10:15.537793",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = F.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        out += identity\n",
    "        out = F.relu(out)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c7e82bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T10:10:15.552672Z",
     "iopub.status.busy": "2024-06-17T10:10:15.552276Z",
     "iopub.status.idle": "2024-06-17T10:10:15.562269Z",
     "shell.execute_reply": "2024-06-17T10:10:15.561411Z"
    },
    "papermill": {
     "duration": 0.017399,
     "end_time": "2024-06-17T10:10:15.564282",
     "exception": false,
     "start_time": "2024-06-17T10:10:15.546883",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DEPTHWISE AND POINTWISE CONV\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.depthwise_conv1 = nn.Conv2d(in_channels, in_channels, kernel_size=3, stride=stride, padding=1, groups=in_channels, bias=False)\n",
    "        self.pointwise_conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        self.depthwise_conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, groups=out_channels, bias=False)\n",
    "        self.pointwise_conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=1, stride=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out = self.depthwise_conv1(x)\n",
    "        out = self.pointwise_conv1(out)\n",
    "        out = self.bn1(out)\n",
    "        out = F.relu(out)\n",
    "\n",
    "        out = self.depthwise_conv2(out)\n",
    "        out = self.pointwise_conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        out += identity\n",
    "        out = F.relu(out)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a0a2b6f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T10:10:15.574576Z",
     "iopub.status.busy": "2024-06-17T10:10:15.574313Z",
     "iopub.status.idle": "2024-06-17T10:10:15.587123Z",
     "shell.execute_reply": "2024-06-17T10:10:15.586429Z"
    },
    "papermill": {
     "duration": 0.020218,
     "end_time": "2024-06-17T10:10:15.589086",
     "exception": false,
     "start_time": "2024-06-17T10:10:15.568868",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes=2):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 64\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, out_channels, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.in_channels != out_channels:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.in_channels, out_channels, stride, downsample))\n",
    "        self.in_channels = out_channels\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.in_channels, out_channels))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30c773db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T10:10:15.599187Z",
     "iopub.status.busy": "2024-06-17T10:10:15.598916Z",
     "iopub.status.idle": "2024-06-17T10:11:12.641974Z",
     "shell.execute_reply": "2024-06-17T10:11:12.641115Z"
    },
    "papermill": {
     "duration": 57.05086,
     "end_time": "2024-06-17T10:11:12.644455",
     "exception": false,
     "start_time": "2024-06-17T10:10:15.593595",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "aug_transforms = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    #transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(degrees=10), \n",
    "    #transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "])\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert(\"RGB\")  # Ensure the image is in RGB mode\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "    \n",
    "def list_image_paths(directory):\n",
    "    return [os.path.join(directory, f) for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f)) and f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "def generate_augmented_dataset(original_dataset, num_augmented_images_per_class, transform):\n",
    "    augmented_images = []\n",
    "    augmented_labels = []\n",
    "    for label in [0, 1]:\n",
    "        counter = 0\n",
    "        while counter < num_augmented_images_per_class:\n",
    "            for img_path, lbl in zip(original_dataset.image_paths, original_dataset.labels):\n",
    "                if lbl == label:\n",
    "                    image = Image.open(img_path).convert(\"RGB\")\n",
    "                    augmented_img = transform(image)\n",
    "                    augmented_images.append(augmented_img)\n",
    "                    augmented_labels.append(lbl)\n",
    "                    counter += 1\n",
    "                    if counter >= num_augmented_images_per_class:\n",
    "                        break\n",
    "    return augmented_images, augmented_labels\n",
    "\n",
    "# List image paths for each class\n",
    "class_0_image_paths = list_image_paths('/kaggle/input/ml-final-dataset/dataset/train/adults')\n",
    "class_1_image_paths = list_image_paths('/kaggle/input/ml-final-dataset/dataset/train/children')\n",
    "class_0_labels = [0] * len(class_0_image_paths)\n",
    "class_1_labels = [1] * len(class_1_image_paths)\n",
    "\n",
    "# Combine both classes' image paths and labels\n",
    "all_image_paths = class_0_image_paths + class_1_image_paths\n",
    "all_labels = class_0_labels + class_1_labels\n",
    "\n",
    "# Create the original dataset\n",
    "original_dataset = CustomDataset(image_paths=all_image_paths, labels=all_labels, transform=None)\n",
    "\n",
    "# Number of augmented images generated per class\n",
    "num_augmented_images_per_class = 6000\n",
    "augmented_images, augmented_labels = generate_augmented_dataset(original_dataset, num_augmented_images_per_class, aug_transforms)\n",
    "\n",
    "# Create a dataset from augmented images and labels\n",
    "augmented_dataset = [(img, lbl) for img, lbl in zip(augmented_images, augmented_labels)]\n",
    "\n",
    "# Custom dataset for augmented data\n",
    "class AugmentedDataset(Dataset):\n",
    "    def __init__(self, augmented_data):\n",
    "        self.augmented_data = augmented_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.augmented_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image, label = self.augmented_data[idx]\n",
    "        return image, label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8b786b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T10:11:12.655548Z",
     "iopub.status.busy": "2024-06-17T10:11:12.655239Z",
     "iopub.status.idle": "2024-06-17T10:11:12.693410Z",
     "shell.execute_reply": "2024-06-17T10:11:12.692742Z"
    },
    "papermill": {
     "duration": 0.045774,
     "end_time": "2024-06-17T10:11:12.695305",
     "exception": false,
     "start_time": "2024-06-17T10:11:12.649531",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 150\n",
    "\n",
    "# Create dataset and DataLoader\n",
    "augmented_dataset = AugmentedDataset(augmented_dataset)\n",
    "train_loader = DataLoader(augmented_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Define transformations for the dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "# Load dataset\n",
    "#train_dataset = datasets.ImageFolder(root='/kaggle/input/ml-final-dataset/dataset/train', transform=transform)\n",
    "test_dataset = datasets.ImageFolder(root='/kaggle/input/ml-final-dataset/dataset/test', transform=transform)\n",
    "\n",
    "#train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cdb68fd1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T10:11:12.705455Z",
     "iopub.status.busy": "2024-06-17T10:11:12.704726Z",
     "iopub.status.idle": "2024-06-17T10:11:12.988295Z",
     "shell.execute_reply": "2024-06-17T10:11:12.987424Z"
    },
    "papermill": {
     "duration": 0.291021,
     "end_time": "2024-06-17T10:11:12.990642",
     "exception": false,
     "start_time": "2024-06-17T10:11:12.699621",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = ResNet(ResBlock, [2, 2, 2, 2], num_classes=2)\n",
    "# Transfer model to GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8429375e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T09:57:26.689340Z",
     "iopub.status.busy": "2024-06-17T09:57:26.688530Z",
     "iopub.status.idle": "2024-06-17T10:04:12.223193Z",
     "shell.execute_reply": "2024-06-17T10:04:12.222286Z",
     "shell.execute_reply.started": "2024-06-17T09:57:26.689307Z"
    },
    "papermill": {
     "duration": 0.004299,
     "end_time": "2024-06-17T10:11:12.999534",
     "exception": false,
     "start_time": "2024-06-17T10:11:12.995235",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 15\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    # Use tqdm to create a progress bar for the data loader\n",
    "    for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{num_epochs}\", unit=\"batch\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(train_loader):.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05b484b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T10:11:13.009729Z",
     "iopub.status.busy": "2024-06-17T10:11:13.009237Z",
     "iopub.status.idle": "2024-06-17T10:11:14.590118Z",
     "shell.execute_reply": "2024-06-17T10:11:14.589215Z"
    },
    "papermill": {
     "duration": 1.588137,
     "end_time": "2024-06-17T10:11:14.592245",
     "exception": false,
     "start_time": "2024-06-17T10:11:13.004108",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 50.00%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test dataset\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Test Accuracy: {100 * correct / total:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9a6ef2c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T10:11:14.602461Z",
     "iopub.status.busy": "2024-06-17T10:11:14.602158Z",
     "iopub.status.idle": "2024-06-17T10:11:28.358823Z",
     "shell.execute_reply": "2024-06-17T10:11:28.357538Z"
    },
    "papermill": {
     "duration": 13.764187,
     "end_time": "2024-06-17T10:11:28.360994",
     "exception": false,
     "start_time": "2024-06-17T10:11:14.596807",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchprofile\r\n",
      "  Downloading torchprofile-0.0.4-py3-none-any.whl.metadata (303 bytes)\r\n",
      "Collecting torchsummary\r\n",
      "  Downloading torchsummary-1.5.1-py3-none-any.whl.metadata (296 bytes)\r\n",
      "Requirement already satisfied: numpy>=1.14 in /opt/conda/lib/python3.10/site-packages (from torchprofile) (1.26.4)\r\n",
      "Requirement already satisfied: torch>=1.4 in /opt/conda/lib/python3.10/site-packages (from torchprofile) (2.1.2)\r\n",
      "Requirement already satisfied: torchvision>=0.4 in /opt/conda/lib/python3.10/site-packages (from torchprofile) (0.16.2)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.4->torchprofile) (3.13.1)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.4->torchprofile) (4.9.0)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.4->torchprofile) (1.12.1)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.4->torchprofile) (3.2.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4->torchprofile) (3.1.2)\r\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.4->torchprofile) (2024.3.1)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision>=0.4->torchprofile) (2.32.3)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision>=0.4->torchprofile) (9.5.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.4->torchprofile) (2.1.3)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.4->torchprofile) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.4->torchprofile) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.4->torchprofile) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.4->torchprofile) (2024.2.2)\r\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.4->torchprofile) (1.3.0)\r\n",
      "Downloading torchprofile-0.0.4-py3-none-any.whl (7.7 kB)\r\n",
      "Downloading torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\r\n",
      "Installing collected packages: torchsummary, torchprofile\r\n",
      "Successfully installed torchprofile-0.0.4 torchsummary-1.5.1\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torchprofile torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f5b59ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T10:11:28.373606Z",
     "iopub.status.busy": "2024-06-17T10:11:28.372803Z",
     "iopub.status.idle": "2024-06-17T10:11:28.650865Z",
     "shell.execute_reply": "2024-06-17T10:11:28.649888Z"
    },
    "papermill": {
     "duration": 0.286478,
     "end_time": "2024-06-17T10:11:28.652821",
     "exception": false,
     "start_time": "2024-06-17T10:11:28.366343",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable_params =  1443202\n",
      "all_params =  1443202\n",
      "FLOPs: 0.34 GFLOPs\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "import torchvision.models as models\n",
    "from torchprofile import profile_macs\n",
    "# Calculate the number of trainable parameters and all parameters\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "all_params = sum(p.numel() for p in model.parameters())\n",
    "\n",
    "print('trainable_params = ', trainable_params)\n",
    "print('all_params = ', all_params)\n",
    "\n",
    "# Create a dummy input tensor with the same size as the input images\n",
    "input_tensor = torch.randn(1, 3, 224, 224).to(device)\n",
    "\n",
    "# Calculate FLOPs\n",
    "flops = profile_macs(model, input_tensor)\n",
    "print(f'FLOPs: {flops / 1e9:.2f} GFLOPs')  # Convert to GFLOPs (GigaFLOPs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53835f60",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T10:11:28.664790Z",
     "iopub.status.busy": "2024-06-17T10:11:28.664527Z",
     "iopub.status.idle": "2024-06-17T10:11:28.668292Z",
     "shell.execute_reply": "2024-06-17T10:11:28.667537Z"
    },
    "papermill": {
     "duration": 0.01193,
     "end_time": "2024-06-17T10:11:28.670171",
     "exception": false,
     "start_time": "2024-06-17T10:11:28.658241",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#torch.save(model, '/kaggle/working/2024_06_17_ResNet.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2614793",
   "metadata": {
    "papermill": {
     "duration": 0.00515,
     "end_time": "2024-06-17T10:11:28.680608",
     "exception": false,
     "start_time": "2024-06-17T10:11:28.675458",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 5190382,
     "sourceId": 8662607,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30733,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 84.10627,
   "end_time": "2024-06-17T10:11:31.479241",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-06-17T10:10:07.372971",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
