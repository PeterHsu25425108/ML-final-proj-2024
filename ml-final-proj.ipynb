{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42def069",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-06-15T14:30:46.569189Z",
     "iopub.status.busy": "2024-06-15T14:30:46.568923Z",
     "iopub.status.idle": "2024-06-15T14:30:51.980090Z",
     "shell.execute_reply": "2024-06-15T14:30:51.979180Z"
    },
    "papermill": {
     "duration": 5.42029,
     "end_time": "2024-06-15T14:30:51.984145",
     "exception": false,
     "start_time": "2024-06-15T14:30:46.563855",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/ml-final-dataset/dataset/test/adults/20.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/adults/6.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/adults/76.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/adults/71.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/adults/5.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/adults/8.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/adults/84.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/adults/85.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/adults/67.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/adults/82.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/adults/30.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/adults/10.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/adults/0.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/adults/62.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/adults/61.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/adults/73.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/adults/60.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/adults/9.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/adults/1.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/adults/69.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/adults/75.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/adults/81.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/adults/65.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/adults/29.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/adults/79.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/adults/16.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/adults/23.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/adults/7.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/adults/77.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/adults/80.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/adults/28.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/adults/22.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/adults/24.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/adults/88.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/adults/64.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/adults/13.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/adults/74.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/adults/68.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/adults/83.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/adults/72.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/adults/17.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/adults/26.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/adults/86.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/adults/15.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/adults/12.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/adults/11.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/adults/70.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/adults/27.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/adults/21.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/adults/4.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/adults/3.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/adults/63.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/adults/19.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/adults/87.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/adults/14.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/adults/18.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/adults/78.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/adults/66.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/adults/2.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/adults/25.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/children/20.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/children/6.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/children/76.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/children/71.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/children/5.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/children/8.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/children/84.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/children/85.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/children/67.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/children/82.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/children/30.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/children/10.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/children/0.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/children/62.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/children/61.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/children/73.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/children/60.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/children/9.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/children/1.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/children/69.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/children/75.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/children/81.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/children/65.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/children/29.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/children/79.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/children/16.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/children/23.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/children/7.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/children/77.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/children/80.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/children/28.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/children/22.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/children/24.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/children/88.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/children/64.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/children/13.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/children/74.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/children/68.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/children/83.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/children/72.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/children/17.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/children/26.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/children/86.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/children/15.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/children/12.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/children/11.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/children/70.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/children/27.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/children/21.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/children/4.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/children/3.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/children/63.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/children/19.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/children/87.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/children/14.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/children/18.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/children/78.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/children/66.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/children/2.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/test/children/25.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/208.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/333.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/369.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/275.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/212.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/239.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/150.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/149.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/187.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/355.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/342.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/377.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/272.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/270.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/182.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/215.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/185.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/243.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/153.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/189.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/143.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/327.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/253.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/343.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/131.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/366.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/151.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/260.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/202.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/237.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/273.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/286.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/283.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/359.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/265.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/289.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/361.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/295.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/176.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/279.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/334.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/163.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/160.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/349.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/328.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/211.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/291.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/197.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/234.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/178.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/271.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/251.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/130.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/278.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/156.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/380.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/120.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/290.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/190.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/124.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/353.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/191.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/379.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/313.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/188.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/274.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/375.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/396.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/248.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/123.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/230.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/256.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/247.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/362.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/221.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/167.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/227.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/372.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/388.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/193.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/374.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/152.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/368.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/192.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/382.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/311.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/241.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/397.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/340.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/177.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/186.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/358.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/390.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/299.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/254.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/381.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/393.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/276.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/319.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/137.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/267.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/314.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/127.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/196.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/140.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/235.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/322.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/302.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/179.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/284.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/285.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/387.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/371.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/317.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/356.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/145.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/135.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/246.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/214.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/225.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/252.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/166.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/292.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/159.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/121.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/173.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/378.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/171.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/329.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/258.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/392.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/174.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/261.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/391.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/357.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/332.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/296.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/346.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/308.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/264.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/199.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/310.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/126.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/142.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/339.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/280.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/169.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/194.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/180.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/155.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/344.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/352.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/287.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/269.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/326.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/216.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/158.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/148.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/168.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/263.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/195.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/255.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/281.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/138.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/207.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/209.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/376.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/228.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/323.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/337.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/223.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/350.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/236.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/363.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/336.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/347.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/354.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/154.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/206.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/164.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/338.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/301.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/146.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/161.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/198.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/277.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/331.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/257.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/233.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/139.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/318.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/200.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/321.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/244.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/220.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/394.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/157.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/351.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/183.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/219.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/373.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/240.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/288.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/360.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/242.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/229.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/222.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/330.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/383.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/238.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/165.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/204.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/224.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/141.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/122.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/293.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/305.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/210.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/181.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/259.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/389.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/370.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/399.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/294.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/262.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/132.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/341.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/309.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/365.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/312.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/184.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/300.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/250.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/297.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/125.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/128.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/172.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/384.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/217.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/386.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/348.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/144.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/325.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/385.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/398.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/162.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/231.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/201.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/303.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/282.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/170.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/324.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/175.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/268.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/345.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/316.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/226.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/320.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/367.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/266.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/245.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/335.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/232.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/203.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/298.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/306.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/395.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/307.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/129.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/205.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/133.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/304.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/315.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/134.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/218.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/249.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/213.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/136.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/364.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/adults/147.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/208.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/333.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/369.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/275.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/212.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/239.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/150.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/149.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/187.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/355.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/342.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/377.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/272.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/270.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/182.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/215.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/185.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/243.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/153.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/189.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/143.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/327.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/253.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/343.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/131.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/366.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/151.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/260.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/202.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/237.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/273.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/286.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/283.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/359.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/265.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/289.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/361.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/295.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/176.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/279.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/334.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/163.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/160.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/349.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/328.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/211.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/291.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/197.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/234.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/178.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/271.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/251.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/130.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/278.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/156.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/380.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/120.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/290.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/190.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/124.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/353.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/191.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/379.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/313.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/188.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/274.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/375.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/396.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/248.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/123.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/230.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/256.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/247.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/362.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/221.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/167.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/227.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/372.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/388.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/193.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/374.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/152.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/368.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/192.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/382.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/311.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/241.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/397.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/340.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/177.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/186.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/358.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/390.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/299.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/254.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/381.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/393.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/276.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/319.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/137.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/267.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/314.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/127.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/196.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/140.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/235.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/322.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/302.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/179.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/284.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/285.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/387.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/371.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/317.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/356.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/145.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/135.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/246.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/214.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/225.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/252.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/166.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/292.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/159.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/121.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/173.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/378.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/171.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/329.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/258.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/392.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/174.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/261.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/391.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/357.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/332.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/296.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/346.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/308.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/264.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/199.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/310.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/126.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/142.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/339.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/280.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/169.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/194.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/180.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/155.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/344.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/352.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/287.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/269.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/326.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/216.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/158.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/148.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/168.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/263.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/195.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/255.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/281.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/138.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/207.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/209.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/376.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/228.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/323.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/337.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/223.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/350.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/236.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/363.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/336.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/347.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/354.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/154.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/206.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/164.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/338.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/301.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/146.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/161.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/198.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/277.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/331.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/257.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/233.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/139.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/318.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/200.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/321.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/244.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/220.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/394.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/157.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/351.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/183.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/219.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/373.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/240.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/288.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/360.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/242.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/229.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/222.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/330.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/383.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/238.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/165.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/204.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/224.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/141.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/122.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/293.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/305.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/210.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/181.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/259.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/389.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/370.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/399.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/294.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/262.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/132.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/341.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/309.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/365.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/312.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/184.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/300.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/250.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/297.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/125.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/128.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/172.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/384.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/217.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/386.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/348.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/144.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/325.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/385.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/398.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/162.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/231.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/201.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/303.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/282.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/170.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/324.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/175.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/268.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/345.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/316.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/226.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/320.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/367.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/266.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/245.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/335.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/232.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/203.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/298.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/306.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/395.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/307.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/129.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/205.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/133.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/304.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/315.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/134.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/218.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/249.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/213.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/136.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/364.jpg\n",
      "/kaggle/input/ml-final-dataset/dataset/train/children/147.jpg\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "# use process bar tool\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "541727cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T14:30:51.996408Z",
     "iopub.status.busy": "2024-06-15T14:30:51.995335Z",
     "iopub.status.idle": "2024-06-15T14:30:52.000134Z",
     "shell.execute_reply": "2024-06-15T14:30:51.999442Z"
    },
    "papermill": {
     "duration": 0.011836,
     "end_time": "2024-06-15T14:30:52.001920",
     "exception": false,
     "start_time": "2024-06-15T14:30:51.990084",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53a7023c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T14:30:52.012058Z",
     "iopub.status.busy": "2024-06-15T14:30:52.011274Z",
     "iopub.status.idle": "2024-06-15T14:30:52.023009Z",
     "shell.execute_reply": "2024-06-15T14:30:52.022372Z"
    },
    "papermill": {
     "duration": 0.018584,
     "end_time": "2024-06-15T14:30:52.024838",
     "exception": false,
     "start_time": "2024-06-15T14:30:52.006254",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define transformations for the dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load dataset\n",
    "train_dataset = datasets.ImageFolder(root='/kaggle/input/ml-final-dataset/dataset/train', transform=transform)\n",
    "test_dataset = datasets.ImageFolder(root='/kaggle/input/ml-final-dataset/dataset/test', transform=transform)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7671262d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T14:30:52.034500Z",
     "iopub.status.busy": "2024-06-15T14:30:52.034232Z",
     "iopub.status.idle": "2024-06-15T14:30:52.784469Z",
     "shell.execute_reply": "2024-06-15T14:30:52.783505Z"
    },
    "papermill": {
     "duration": 0.757633,
     "end_time": "2024-06-15T14:30:52.786875",
     "exception": false,
     "start_time": "2024-06-15T14:30:52.029242",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-7f5810bc.pth\n",
      "100%|| 20.5M/20.5M [00:00<00:00, 108MB/s] \n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained EfficientNet model\n",
    "model = models.efficientnet_b0(pretrained=True)\n",
    "for param in model.features.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Modify the final layer to match the number of classes in the final project\n",
    "num_ftrs = model.classifier[1].in_features\n",
    "model.classifier[1] = nn.Linear(num_ftrs, 2)  # Binary classification (2 classes)\n",
    "\n",
    "# Transfer model to GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfa3ac0a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T14:30:52.797798Z",
     "iopub.status.busy": "2024-06-15T14:30:52.797495Z",
     "iopub.status.idle": "2024-06-15T14:31:24.568771Z",
     "shell.execute_reply": "2024-06-15T14:31:24.567856Z"
    },
    "papermill": {
     "duration": 31.778793,
     "end_time": "2024-06-15T14:31:24.570790",
     "exception": false,
     "start_time": "2024-06-15T14:30:52.791997",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|| 18/18 [00:05<00:00,  3.31batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.6586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|| 18/18 [00:03<00:00,  6.00batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Loss: 0.5308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|| 18/18 [00:02<00:00,  6.11batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Loss: 0.4673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|| 18/18 [00:02<00:00,  6.18batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Loss: 0.4294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|| 18/18 [00:02<00:00,  6.22batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Loss: 0.4004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|| 18/18 [00:02<00:00,  6.23batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Loss: 0.4084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|| 18/18 [00:02<00:00,  6.04batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Loss: 0.3750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|| 18/18 [00:02<00:00,  6.14batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Loss: 0.3552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|| 18/18 [00:02<00:00,  6.28batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Loss: 0.3721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|| 18/18 [00:02<00:00,  6.30batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Loss: 0.3700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    # Use tqdm to create a progress bar for the data loader\n",
    "    for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{num_epochs}\", unit=\"batch\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(train_loader):.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7712d313",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T14:31:24.615457Z",
     "iopub.status.busy": "2024-06-15T14:31:24.615133Z",
     "iopub.status.idle": "2024-06-15T14:31:25.542750Z",
     "shell.execute_reply": "2024-06-15T14:31:25.541598Z"
    },
    "papermill": {
     "duration": 0.952769,
     "end_time": "2024-06-15T14:31:25.544866",
     "exception": false,
     "start_time": "2024-06-15T14:31:24.592097",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 75.83%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test dataset\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Test Accuracy: {100 * correct / total:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f1c461c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T14:31:25.590271Z",
     "iopub.status.busy": "2024-06-15T14:31:25.589446Z",
     "iopub.status.idle": "2024-06-15T14:31:28.467823Z",
     "shell.execute_reply": "2024-06-15T14:31:28.466615Z"
    },
    "papermill": {
     "duration": 2.90392,
     "end_time": "2024-06-15T14:31:28.470484",
     "exception": false,
     "start_time": "2024-06-15T14:31:25.566564",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 90.36%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the train dataset\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Train Accuracy: {100 * correct / total:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adab0105",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T14:31:28.516396Z",
     "iopub.status.busy": "2024-06-15T14:31:28.515614Z",
     "iopub.status.idle": "2024-06-15T14:31:28.613173Z",
     "shell.execute_reply": "2024-06-15T14:31:28.612175Z"
    },
    "papermill": {
     "duration": 0.122436,
     "end_time": "2024-06-15T14:31:28.615399",
     "exception": false,
     "start_time": "2024-06-15T14:31:28.492963",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(model, '2024_06_15_trial.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "519bccaf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T14:31:28.664472Z",
     "iopub.status.busy": "2024-06-15T14:31:28.664099Z",
     "iopub.status.idle": "2024-06-15T14:31:28.831520Z",
     "shell.execute_reply": "2024-06-15T14:31:28.830487Z"
    },
    "papermill": {
     "duration": 0.194761,
     "end_time": "2024-06-15T14:31:28.835987",
     "exception": false,
     "start_time": "2024-06-15T14:31:28.641226",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Layers:\n",
      "Sequential(\n",
      "  (0): Conv2dNormActivation(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): SiLU(inplace=True)\n",
      "  )\n",
      "  (1): Sequential(\n",
      "    (0): MBConv(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): SiLU(inplace=True)\n",
      "        )\n",
      "        (1): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): SiLU(inplace=True)\n",
      "          (scale_activation): Sigmoid()\n",
      "        )\n",
      "        (2): Conv2dNormActivation(\n",
      "          (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
      "    )\n",
      "  )\n",
      "  (2): Sequential(\n",
      "    (0): MBConv(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): SiLU(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
      "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): SiLU(inplace=True)\n",
      "        )\n",
      "        (2): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): SiLU(inplace=True)\n",
      "          (scale_activation): Sigmoid()\n",
      "        )\n",
      "        (3): Conv2dNormActivation(\n",
      "          (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (stochastic_depth): StochasticDepth(p=0.0125, mode=row)\n",
      "    )\n",
      "    (1): MBConv(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): SiLU(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): SiLU(inplace=True)\n",
      "        )\n",
      "        (2): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): SiLU(inplace=True)\n",
      "          (scale_activation): Sigmoid()\n",
      "        )\n",
      "        (3): Conv2dNormActivation(\n",
      "          (0): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (stochastic_depth): StochasticDepth(p=0.025, mode=row)\n",
      "    )\n",
      "  )\n",
      "  (3): Sequential(\n",
      "    (0): MBConv(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): SiLU(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): SiLU(inplace=True)\n",
      "        )\n",
      "        (2): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): SiLU(inplace=True)\n",
      "          (scale_activation): Sigmoid()\n",
      "        )\n",
      "        (3): Conv2dNormActivation(\n",
      "          (0): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (stochastic_depth): StochasticDepth(p=0.037500000000000006, mode=row)\n",
      "    )\n",
      "    (1): MBConv(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): SiLU(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
      "          (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): SiLU(inplace=True)\n",
      "        )\n",
      "        (2): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): SiLU(inplace=True)\n",
      "          (scale_activation): Sigmoid()\n",
      "        )\n",
      "        (3): Conv2dNormActivation(\n",
      "          (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (stochastic_depth): StochasticDepth(p=0.05, mode=row)\n",
      "    )\n",
      "  )\n",
      "  (4): Sequential(\n",
      "    (0): MBConv(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): SiLU(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
      "          (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): SiLU(inplace=True)\n",
      "        )\n",
      "        (2): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): SiLU(inplace=True)\n",
      "          (scale_activation): Sigmoid()\n",
      "        )\n",
      "        (3): Conv2dNormActivation(\n",
      "          (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (stochastic_depth): StochasticDepth(p=0.0625, mode=row)\n",
      "    )\n",
      "    (1): MBConv(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): SiLU(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "          (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): SiLU(inplace=True)\n",
      "        )\n",
      "        (2): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): SiLU(inplace=True)\n",
      "          (scale_activation): Sigmoid()\n",
      "        )\n",
      "        (3): Conv2dNormActivation(\n",
      "          (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (stochastic_depth): StochasticDepth(p=0.07500000000000001, mode=row)\n",
      "    )\n",
      "    (2): MBConv(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): SiLU(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "          (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): SiLU(inplace=True)\n",
      "        )\n",
      "        (2): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): SiLU(inplace=True)\n",
      "          (scale_activation): Sigmoid()\n",
      "        )\n",
      "        (3): Conv2dNormActivation(\n",
      "          (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (stochastic_depth): StochasticDepth(p=0.08750000000000001, mode=row)\n",
      "    )\n",
      "  )\n",
      "  (5): Sequential(\n",
      "    (0): MBConv(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): SiLU(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
      "          (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): SiLU(inplace=True)\n",
      "        )\n",
      "        (2): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): SiLU(inplace=True)\n",
      "          (scale_activation): Sigmoid()\n",
      "        )\n",
      "        (3): Conv2dNormActivation(\n",
      "          (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n",
      "    )\n",
      "    (1): MBConv(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): SiLU(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
      "          (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): SiLU(inplace=True)\n",
      "        )\n",
      "        (2): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): SiLU(inplace=True)\n",
      "          (scale_activation): Sigmoid()\n",
      "        )\n",
      "        (3): Conv2dNormActivation(\n",
      "          (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (stochastic_depth): StochasticDepth(p=0.1125, mode=row)\n",
      "    )\n",
      "    (2): MBConv(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): SiLU(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
      "          (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): SiLU(inplace=True)\n",
      "        )\n",
      "        (2): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): SiLU(inplace=True)\n",
      "          (scale_activation): Sigmoid()\n",
      "        )\n",
      "        (3): Conv2dNormActivation(\n",
      "          (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (stochastic_depth): StochasticDepth(p=0.125, mode=row)\n",
      "    )\n",
      "  )\n",
      "  (6): Sequential(\n",
      "    (0): MBConv(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): SiLU(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
      "          (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): SiLU(inplace=True)\n",
      "        )\n",
      "        (2): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): SiLU(inplace=True)\n",
      "          (scale_activation): Sigmoid()\n",
      "        )\n",
      "        (3): Conv2dNormActivation(\n",
      "          (0): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (stochastic_depth): StochasticDepth(p=0.1375, mode=row)\n",
      "    )\n",
      "    (1): MBConv(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): SiLU(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
      "          (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): SiLU(inplace=True)\n",
      "        )\n",
      "        (2): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): SiLU(inplace=True)\n",
      "          (scale_activation): Sigmoid()\n",
      "        )\n",
      "        (3): Conv2dNormActivation(\n",
      "          (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (stochastic_depth): StochasticDepth(p=0.15000000000000002, mode=row)\n",
      "    )\n",
      "    (2): MBConv(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): SiLU(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
      "          (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): SiLU(inplace=True)\n",
      "        )\n",
      "        (2): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): SiLU(inplace=True)\n",
      "          (scale_activation): Sigmoid()\n",
      "        )\n",
      "        (3): Conv2dNormActivation(\n",
      "          (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (stochastic_depth): StochasticDepth(p=0.1625, mode=row)\n",
      "    )\n",
      "    (3): MBConv(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): SiLU(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
      "          (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): SiLU(inplace=True)\n",
      "        )\n",
      "        (2): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): SiLU(inplace=True)\n",
      "          (scale_activation): Sigmoid()\n",
      "        )\n",
      "        (3): Conv2dNormActivation(\n",
      "          (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (stochastic_depth): StochasticDepth(p=0.17500000000000002, mode=row)\n",
      "    )\n",
      "  )\n",
      "  (7): Sequential(\n",
      "    (0): MBConv(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): SiLU(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
      "          (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): SiLU(inplace=True)\n",
      "        )\n",
      "        (2): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): SiLU(inplace=True)\n",
      "          (scale_activation): Sigmoid()\n",
      "        )\n",
      "        (3): Conv2dNormActivation(\n",
      "          (0): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (stochastic_depth): StochasticDepth(p=0.1875, mode=row)\n",
      "    )\n",
      "  )\n",
      "  (8): Conv2dNormActivation(\n",
      "    (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): SiLU(inplace=True)\n",
      "  )\n",
      ")\n",
      "AdaptiveAvgPool2d(output_size=1)\n",
      "Sequential(\n",
      "  (0): Dropout(p=0.2, inplace=True)\n",
      "  (1): Linear(in_features=1280, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(\"Model Layers:\")\n",
    "orig_model = models.efficientnet_b0(pretrained=True)\n",
    "for layer in orig_model.children():\n",
    "    print(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6d6c8f",
   "metadata": {
    "papermill": {
     "duration": 0.021501,
     "end_time": "2024-06-15T14:31:28.880060",
     "exception": false,
     "start_time": "2024-06-15T14:31:28.858559",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 5190382,
     "sourceId": 8662607,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30732,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 46.327112,
   "end_time": "2024-06-15T14:31:30.223328",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-06-15T14:30:43.896216",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
