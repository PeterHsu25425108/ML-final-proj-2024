{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8662607,"sourceType":"datasetVersion","datasetId":5190382}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport torch\nimport torchvision\nimport torchvision.transforms as transforms\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Subset,Dataset\n# use process bar tool\nfrom tqdm import tqdm\nfrom PIL import Image\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","scrolled":true,"execution":{"iopub.status.busy":"2024-06-17T04:37:31.892131Z","iopub.execute_input":"2024-06-17T04:37:31.892476Z","iopub.status.idle":"2024-06-17T04:37:31.911797Z","shell.execute_reply.started":"2024-06-17T04:37:31.892447Z","shell.execute_reply":"2024-06-17T04:37:31.910945Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"/kaggle/input/ml-final-dataset/dataset/test/adults/20.jpg\n/kaggle/input/ml-final-dataset/dataset/test/adults/6.jpg\n/kaggle/input/ml-final-dataset/dataset/test/adults/76.jpg\n/kaggle/input/ml-final-dataset/dataset/test/adults/71.jpg\n/kaggle/input/ml-final-dataset/dataset/test/adults/5.jpg\n/kaggle/input/ml-final-dataset/dataset/test/adults/8.jpg\n/kaggle/input/ml-final-dataset/dataset/test/adults/84.jpg\n/kaggle/input/ml-final-dataset/dataset/test/adults/85.jpg\n/kaggle/input/ml-final-dataset/dataset/test/adults/67.jpg\n/kaggle/input/ml-final-dataset/dataset/test/adults/82.jpg\n/kaggle/input/ml-final-dataset/dataset/test/adults/30.jpg\n/kaggle/input/ml-final-dataset/dataset/test/adults/10.jpg\n/kaggle/input/ml-final-dataset/dataset/test/adults/0.jpg\n/kaggle/input/ml-final-dataset/dataset/test/adults/62.jpg\n/kaggle/input/ml-final-dataset/dataset/test/adults/61.jpg\n/kaggle/input/ml-final-dataset/dataset/test/adults/73.jpg\n/kaggle/input/ml-final-dataset/dataset/test/adults/60.jpg\n/kaggle/input/ml-final-dataset/dataset/test/adults/9.jpg\n/kaggle/input/ml-final-dataset/dataset/test/adults/1.jpg\n/kaggle/input/ml-final-dataset/dataset/test/adults/69.jpg\n/kaggle/input/ml-final-dataset/dataset/test/adults/75.jpg\n/kaggle/input/ml-final-dataset/dataset/test/adults/81.jpg\n/kaggle/input/ml-final-dataset/dataset/test/adults/65.jpg\n/kaggle/input/ml-final-dataset/dataset/test/adults/29.jpg\n/kaggle/input/ml-final-dataset/dataset/test/adults/79.jpg\n/kaggle/input/ml-final-dataset/dataset/test/adults/16.jpg\n/kaggle/input/ml-final-dataset/dataset/test/adults/23.jpg\n/kaggle/input/ml-final-dataset/dataset/test/adults/7.jpg\n/kaggle/input/ml-final-dataset/dataset/test/adults/77.jpg\n/kaggle/input/ml-final-dataset/dataset/test/adults/80.jpg\n/kaggle/input/ml-final-dataset/dataset/test/adults/28.jpg\n/kaggle/input/ml-final-dataset/dataset/test/adults/22.jpg\n/kaggle/input/ml-final-dataset/dataset/test/adults/24.jpg\n/kaggle/input/ml-final-dataset/dataset/test/adults/88.jpg\n/kaggle/input/ml-final-dataset/dataset/test/adults/64.jpg\n/kaggle/input/ml-final-dataset/dataset/test/adults/13.jpg\n/kaggle/input/ml-final-dataset/dataset/test/adults/74.jpg\n/kaggle/input/ml-final-dataset/dataset/test/adults/68.jpg\n/kaggle/input/ml-final-dataset/dataset/test/adults/83.jpg\n/kaggle/input/ml-final-dataset/dataset/test/adults/72.jpg\n/kaggle/input/ml-final-dataset/dataset/test/adults/17.jpg\n/kaggle/input/ml-final-dataset/dataset/test/adults/26.jpg\n/kaggle/input/ml-final-dataset/dataset/test/adults/86.jpg\n/kaggle/input/ml-final-dataset/dataset/test/adults/15.jpg\n/kaggle/input/ml-final-dataset/dataset/test/adults/12.jpg\n/kaggle/input/ml-final-dataset/dataset/test/adults/11.jpg\n/kaggle/input/ml-final-dataset/dataset/test/adults/70.jpg\n/kaggle/input/ml-final-dataset/dataset/test/adults/27.jpg\n/kaggle/input/ml-final-dataset/dataset/test/adults/21.jpg\n/kaggle/input/ml-final-dataset/dataset/test/adults/4.jpg\n/kaggle/input/ml-final-dataset/dataset/test/adults/3.jpg\n/kaggle/input/ml-final-dataset/dataset/test/adults/63.jpg\n/kaggle/input/ml-final-dataset/dataset/test/adults/19.jpg\n/kaggle/input/ml-final-dataset/dataset/test/adults/87.jpg\n/kaggle/input/ml-final-dataset/dataset/test/adults/14.jpg\n/kaggle/input/ml-final-dataset/dataset/test/adults/18.jpg\n/kaggle/input/ml-final-dataset/dataset/test/adults/78.jpg\n/kaggle/input/ml-final-dataset/dataset/test/adults/66.jpg\n/kaggle/input/ml-final-dataset/dataset/test/adults/2.jpg\n/kaggle/input/ml-final-dataset/dataset/test/adults/25.jpg\n/kaggle/input/ml-final-dataset/dataset/test/children/20.jpg\n/kaggle/input/ml-final-dataset/dataset/test/children/6.jpg\n/kaggle/input/ml-final-dataset/dataset/test/children/76.jpg\n/kaggle/input/ml-final-dataset/dataset/test/children/71.jpg\n/kaggle/input/ml-final-dataset/dataset/test/children/5.jpg\n/kaggle/input/ml-final-dataset/dataset/test/children/8.jpg\n/kaggle/input/ml-final-dataset/dataset/test/children/84.jpg\n/kaggle/input/ml-final-dataset/dataset/test/children/85.jpg\n/kaggle/input/ml-final-dataset/dataset/test/children/67.jpg\n/kaggle/input/ml-final-dataset/dataset/test/children/82.jpg\n/kaggle/input/ml-final-dataset/dataset/test/children/30.jpg\n/kaggle/input/ml-final-dataset/dataset/test/children/10.jpg\n/kaggle/input/ml-final-dataset/dataset/test/children/0.jpg\n/kaggle/input/ml-final-dataset/dataset/test/children/62.jpg\n/kaggle/input/ml-final-dataset/dataset/test/children/61.jpg\n/kaggle/input/ml-final-dataset/dataset/test/children/73.jpg\n/kaggle/input/ml-final-dataset/dataset/test/children/60.jpg\n/kaggle/input/ml-final-dataset/dataset/test/children/9.jpg\n/kaggle/input/ml-final-dataset/dataset/test/children/1.jpg\n/kaggle/input/ml-final-dataset/dataset/test/children/69.jpg\n/kaggle/input/ml-final-dataset/dataset/test/children/75.jpg\n/kaggle/input/ml-final-dataset/dataset/test/children/81.jpg\n/kaggle/input/ml-final-dataset/dataset/test/children/65.jpg\n/kaggle/input/ml-final-dataset/dataset/test/children/29.jpg\n/kaggle/input/ml-final-dataset/dataset/test/children/79.jpg\n/kaggle/input/ml-final-dataset/dataset/test/children/16.jpg\n/kaggle/input/ml-final-dataset/dataset/test/children/23.jpg\n/kaggle/input/ml-final-dataset/dataset/test/children/7.jpg\n/kaggle/input/ml-final-dataset/dataset/test/children/77.jpg\n/kaggle/input/ml-final-dataset/dataset/test/children/80.jpg\n/kaggle/input/ml-final-dataset/dataset/test/children/28.jpg\n/kaggle/input/ml-final-dataset/dataset/test/children/22.jpg\n/kaggle/input/ml-final-dataset/dataset/test/children/24.jpg\n/kaggle/input/ml-final-dataset/dataset/test/children/88.jpg\n/kaggle/input/ml-final-dataset/dataset/test/children/64.jpg\n/kaggle/input/ml-final-dataset/dataset/test/children/13.jpg\n/kaggle/input/ml-final-dataset/dataset/test/children/74.jpg\n/kaggle/input/ml-final-dataset/dataset/test/children/68.jpg\n/kaggle/input/ml-final-dataset/dataset/test/children/83.jpg\n/kaggle/input/ml-final-dataset/dataset/test/children/72.jpg\n/kaggle/input/ml-final-dataset/dataset/test/children/17.jpg\n/kaggle/input/ml-final-dataset/dataset/test/children/26.jpg\n/kaggle/input/ml-final-dataset/dataset/test/children/86.jpg\n/kaggle/input/ml-final-dataset/dataset/test/children/15.jpg\n/kaggle/input/ml-final-dataset/dataset/test/children/12.jpg\n/kaggle/input/ml-final-dataset/dataset/test/children/11.jpg\n/kaggle/input/ml-final-dataset/dataset/test/children/70.jpg\n/kaggle/input/ml-final-dataset/dataset/test/children/27.jpg\n/kaggle/input/ml-final-dataset/dataset/test/children/21.jpg\n/kaggle/input/ml-final-dataset/dataset/test/children/4.jpg\n/kaggle/input/ml-final-dataset/dataset/test/children/3.jpg\n/kaggle/input/ml-final-dataset/dataset/test/children/63.jpg\n/kaggle/input/ml-final-dataset/dataset/test/children/19.jpg\n/kaggle/input/ml-final-dataset/dataset/test/children/87.jpg\n/kaggle/input/ml-final-dataset/dataset/test/children/14.jpg\n/kaggle/input/ml-final-dataset/dataset/test/children/18.jpg\n/kaggle/input/ml-final-dataset/dataset/test/children/78.jpg\n/kaggle/input/ml-final-dataset/dataset/test/children/66.jpg\n/kaggle/input/ml-final-dataset/dataset/test/children/2.jpg\n/kaggle/input/ml-final-dataset/dataset/test/children/25.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/208.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/333.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/369.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/275.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/212.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/239.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/150.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/149.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/187.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/355.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/342.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/377.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/272.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/270.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/182.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/215.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/185.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/243.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/153.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/189.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/143.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/327.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/253.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/343.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/131.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/366.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/151.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/260.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/202.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/237.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/273.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/286.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/283.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/359.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/265.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/289.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/361.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/295.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/176.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/279.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/334.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/163.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/160.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/349.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/328.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/211.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/291.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/197.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/234.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/178.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/271.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/251.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/130.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/278.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/156.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/380.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/120.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/290.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/190.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/124.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/353.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/191.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/379.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/313.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/188.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/274.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/375.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/396.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/248.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/123.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/230.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/256.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/247.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/362.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/221.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/167.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/227.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/372.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/388.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/193.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/374.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/152.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/368.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/192.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/382.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/311.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/241.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/397.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/340.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/177.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/186.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/358.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/390.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/299.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/254.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/381.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/393.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/276.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/319.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/137.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/267.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/314.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/127.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/196.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/140.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/235.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/322.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/302.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/179.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/284.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/285.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/387.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/371.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/317.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/356.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/145.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/135.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/246.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/214.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/225.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/252.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/166.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/292.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/159.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/121.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/173.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/378.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/171.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/329.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/258.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/392.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/174.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/261.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/391.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/357.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/332.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/296.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/346.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/308.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/264.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/199.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/310.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/126.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/142.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/339.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/280.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/169.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/194.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/180.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/155.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/344.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/352.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/287.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/269.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/326.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/216.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/158.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/148.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/168.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/263.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/195.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/255.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/281.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/138.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/207.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/209.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/376.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/228.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/323.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/337.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/223.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/350.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/236.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/363.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/336.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/347.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/354.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/154.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/206.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/164.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/338.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/301.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/146.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/161.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/198.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/277.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/331.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/257.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/233.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/139.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/318.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/200.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/321.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/244.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/220.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/394.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/157.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/351.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/183.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/219.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/373.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/240.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/288.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/360.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/242.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/229.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/222.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/330.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/383.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/238.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/165.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/204.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/224.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/141.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/122.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/293.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/305.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/210.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/181.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/259.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/389.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/370.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/399.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/294.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/262.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/132.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/341.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/309.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/365.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/312.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/184.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/300.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/250.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/297.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/125.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/128.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/172.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/384.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/217.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/386.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/348.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/144.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/325.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/385.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/398.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/162.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/231.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/201.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/303.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/282.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/170.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/324.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/175.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/268.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/345.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/316.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/226.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/320.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/367.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/266.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/245.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/335.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/232.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/203.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/298.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/306.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/395.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/307.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/129.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/205.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/133.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/304.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/315.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/134.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/218.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/249.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/213.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/136.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/364.jpg\n/kaggle/input/ml-final-dataset/dataset/train/adults/147.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/208.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/333.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/369.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/275.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/212.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/239.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/150.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/149.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/187.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/355.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/342.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/377.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/272.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/270.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/182.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/215.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/185.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/243.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/153.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/189.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/143.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/327.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/253.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/343.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/131.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/366.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/151.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/260.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/202.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/237.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/273.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/286.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/283.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/359.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/265.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/289.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/361.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/295.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/176.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/279.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/334.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/163.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/160.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/349.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/328.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/211.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/291.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/197.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/234.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/178.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/271.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/251.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/130.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/278.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/156.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/380.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/120.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/290.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/190.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/124.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/353.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/191.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/379.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/313.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/188.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/274.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/375.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/396.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/248.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/123.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/230.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/256.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/247.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/362.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/221.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/167.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/227.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/372.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/388.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/193.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/374.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/152.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/368.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/192.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/382.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/311.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/241.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/397.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/340.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/177.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/186.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/358.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/390.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/299.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/254.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/381.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/393.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/276.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/319.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/137.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/267.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/314.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/127.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/196.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/140.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/235.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/322.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/302.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/179.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/284.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/285.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/387.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/371.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/317.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/356.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/145.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/135.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/246.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/214.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/225.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/252.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/166.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/292.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/159.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/121.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/173.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/378.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/171.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/329.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/258.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/392.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/174.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/261.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/391.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/357.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/332.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/296.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/346.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/308.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/264.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/199.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/310.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/126.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/142.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/339.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/280.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/169.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/194.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/180.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/155.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/344.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/352.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/287.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/269.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/326.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/216.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/158.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/148.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/168.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/263.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/195.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/255.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/281.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/138.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/207.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/209.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/376.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/228.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/323.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/337.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/223.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/350.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/236.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/363.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/336.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/347.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/354.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/154.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/206.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/164.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/338.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/301.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/146.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/161.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/198.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/277.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/331.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/257.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/233.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/139.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/318.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/200.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/321.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/244.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/220.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/394.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/157.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/351.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/183.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/219.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/373.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/240.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/288.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/360.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/242.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/229.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/222.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/330.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/383.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/238.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/165.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/204.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/224.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/141.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/122.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/293.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/305.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/210.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/181.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/259.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/389.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/370.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/399.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/294.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/262.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/132.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/341.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/309.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/365.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/312.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/184.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/300.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/250.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/297.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/125.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/128.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/172.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/384.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/217.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/386.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/348.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/144.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/325.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/385.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/398.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/162.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/231.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/201.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/303.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/282.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/170.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/324.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/175.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/268.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/345.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/316.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/226.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/320.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/367.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/266.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/245.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/335.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/232.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/203.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/298.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/306.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/395.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/307.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/129.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/205.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/133.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/304.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/315.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/134.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/218.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/249.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/213.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/136.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/364.jpg\n/kaggle/input/ml-final-dataset/dataset/train/children/147.jpg\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torchvision.models as models\nfrom torchvision import transforms, datasets\nfrom torch.utils.data import DataLoader","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-06-17T04:37:33.573996Z","iopub.execute_input":"2024-06-17T04:37:33.574599Z","iopub.status.idle":"2024-06-17T04:37:33.579021Z","shell.execute_reply.started":"2024-06-17T04:37:33.574568Z","shell.execute_reply":"2024-06-17T04:37:33.578093Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"aug_transforms = transforms.Compose([\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomVerticalFlip(),\n    transforms.RandomRotation(degrees=10), \n    #transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n    transforms.RandomResizedCrop(224),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n])\n\nclass CustomDataset(Dataset):\n    def __init__(self, image_paths, labels, transform=None):\n        self.image_paths = image_paths\n        self.labels = labels\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, idx):\n        img_path = self.image_paths[idx]\n        image = Image.open(img_path)\n        label = self.labels[idx]\n        if self.transform:\n            image = self.transform(image)\n        return image, label\n    \ndef list_image_paths(directory):\n    return [os.path.join(directory, f) for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f))]\n\n# List image paths for each class\nclass_0_image_paths = list_image_paths('/kaggle/input/ml-final-dataset/dataset/train/adults')\nclass_1_image_paths = list_image_paths('/kaggle/input/ml-final-dataset/dataset/train/children')\nclass_0_labels = [0] * len(class_0_image_paths)\nclass_1_labels = [1] * len(class_1_image_paths)\n\n# Combine both classes' image paths and labels\nall_image_paths = class_0_image_paths + class_1_image_paths\nall_labels = class_0_labels + class_1_labels\n\noriginal_dataset = CustomDataset(image_paths=all_image_paths, labels=all_labels, transform=None)\n\ndef generate_augmented_dataset(original_dataset, num_augmented_images_per_class, transform):\n    augmented_images = []\n    augmented_labels = []\n    for label in [0, 1]:\n        counter = 0\n        while counter < num_augmented_images_per_class:\n            for img, lbl in original_dataset:\n                if lbl == label:\n                    augmented_img = transform(img)\n                    augmented_images.append(transforms.ToPILImage(augmented_img))\n                    augmented_labels.append(lbl)\n                    counter += 1\n                    if counter >= num_augmented_images_per_class:\n                        break\n    return augmented_images, augmented_labels\n\n# Number of augmented image generated\nnum_augmented_images_per_class = 720\naugmented_images, augmented_labels = generate_augmented_dataset(original_dataset, num_augmented_images_per_class, aug_transforms)\n\ncombined_images = all_image_paths + augmented_images\ncombined_labels = all_labels + augmented_labels\n\ncombined_dataset = CustomDataset(image_paths=combined_images, labels=combined_labels, transform = None)\ntrain_loader = DataLoader(combined_dataset, batch_size=32, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-06-17T04:51:36.624220Z","iopub.execute_input":"2024-06-17T04:51:36.624961Z","iopub.status.idle":"2024-06-17T04:51:44.117644Z","shell.execute_reply.started":"2024-06-17T04:51:36.624921Z","shell.execute_reply":"2024-06-17T04:51:44.116800Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# Define transformations for the dataset\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n])\n\n# Load dataset\n#train_dataset = datasets.ImageFolder(root='/kaggle/input/ml-final-dataset/dataset/train', transform=transform)\ntest_dataset = datasets.ImageFolder(root='/kaggle/input/ml-final-dataset/dataset/test', transform=transform)\n\n#train_loader = DataLoader(dataset=train_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(dataset=test_dataset, batch_size=32, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-06-17T04:51:44.119112Z","iopub.execute_input":"2024-06-17T04:51:44.119393Z","iopub.status.idle":"2024-06-17T04:51:44.127742Z","shell.execute_reply.started":"2024-06-17T04:51:44.119368Z","shell.execute_reply":"2024-06-17T04:51:44.126891Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load pre-trained EfficientNet model\nmodel = models.efficientnet_b0(pretrained=True)\n#for param in model.features.parameters():\n#    param.requires_grad = False\n#model = torch.load('/kaggle/working/2024_06_15_trial.pt')\n\n# Modify the final layer to match the number of classes in the final project\nnum_ftrs = model.classifier[1].in_features\nmodel.classifier[1] = nn.Linear(num_ftrs, 2)  # Binary classification (2 classes)\n\n# Transfer model to GPU if available\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = model.to(device)\n\n# Define loss function and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)","metadata":{"execution":{"iopub.status.busy":"2024-06-17T04:51:44.128843Z","iopub.execute_input":"2024-06-17T04:51:44.129160Z","iopub.status.idle":"2024-06-17T04:51:44.478258Z","shell.execute_reply.started":"2024-06-17T04:51:44.129128Z","shell.execute_reply":"2024-06-17T04:51:44.477285Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# Training loop\nnum_epochs = 20\nfor epoch in range(num_epochs):\n    model.train()\n    running_loss = 0.0\n    \n    # Use tqdm to create a progress bar for the data loader\n    for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{num_epochs}\", unit=\"batch\"):\n        images, labels = images.to(device), labels.to(device)\n        \n        # Zero the parameter gradients\n        optimizer.zero_grad()\n        \n        # Forward pass\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        \n        # Backward pass and optimization\n        loss.backward()\n        optimizer.step()\n        \n        running_loss += loss.item()\n    \n    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(train_loader):.4f}')\n","metadata":{"execution":{"iopub.status.busy":"2024-06-17T04:51:45.197858Z","iopub.execute_input":"2024-06-17T04:51:45.198649Z","iopub.status.idle":"2024-06-17T04:51:45.361747Z","shell.execute_reply.started":"2024-06-17T04:51:45.198615Z","shell.execute_reply":"2024-06-17T04:51:45.360322Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stderr","text":"Epoch 1/20:   0%|          | 0/63 [00:00<?, ?batch/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/PIL/Image.py:3240\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3239\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3240\u001b[0m     \u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseek\u001b[49m(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m   3241\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mAttributeError\u001b[39;00m, io\u001b[38;5;241m.\u001b[39mUnsupportedOperation):\n","\u001b[0;31mAttributeError\u001b[0m: 'ToPILImage' object has no attribute 'seek'","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[27], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Use tqdm to create a progress bar for the data loader\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m images, labels \u001b[38;5;129;01min\u001b[39;00m tqdm(train_loader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m      9\u001b[0m     images, labels \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# Zero the parameter gradients\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n","Cell \u001b[0;32mIn[24], line 22\u001b[0m, in \u001b[0;36mCustomDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[1;32m     21\u001b[0m     img_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_paths[idx]\n\u001b[0;32m---> 22\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m     label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels[idx]\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/PIL/Image.py:3242\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3240\u001b[0m     fp\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m   3241\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mAttributeError\u001b[39;00m, io\u001b[38;5;241m.\u001b[39mUnsupportedOperation):\n\u001b[0;32m-> 3242\u001b[0m     fp \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mBytesIO(\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m())\n\u001b[1;32m   3243\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   3245\u001b[0m prefix \u001b[38;5;241m=\u001b[39m fp\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;241m16\u001b[39m)\n","\u001b[0;31mAttributeError\u001b[0m: 'ToPILImage' object has no attribute 'read'"],"ename":"AttributeError","evalue":"'ToPILImage' object has no attribute 'read'","output_type":"error"}]},{"cell_type":"code","source":"# Evaluate the model on the test dataset\nmodel.eval()\ncorrect = 0\ntotal = 0\nwith torch.no_grad():\n    for images, labels in test_loader:\n        images, labels = images.to(device), labels.to(device)\n        outputs = model(images)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\nprint(f'Test Accuracy: {100 * correct / total:.2f}%')","metadata":{"execution":{"iopub.status.busy":"2024-06-17T04:01:24.043163Z","iopub.execute_input":"2024-06-17T04:01:24.044090Z","iopub.status.idle":"2024-06-17T04:01:25.432822Z","shell.execute_reply.started":"2024-06-17T04:01:24.044043Z","shell.execute_reply":"2024-06-17T04:01:25.431881Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Test Accuracy: 87.50%\n","output_type":"stream"}]},{"cell_type":"code","source":"# Evaluate the model on the train dataset\nmodel.eval()\ncorrect = 0\ntotal = 0\nwith torch.no_grad():\n    for images, labels in train_loader:\n        images, labels = images.to(device), labels.to(device)\n        outputs = model(images)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\nprint(f'Train Accuracy: {100 * correct / total:.2f}%')","metadata":{"execution":{"iopub.status.busy":"2024-06-15T14:59:06.608788Z","iopub.execute_input":"2024-06-15T14:59:06.609164Z","iopub.status.idle":"2024-06-15T14:59:09.537471Z","shell.execute_reply.started":"2024-06-15T14:59:06.609132Z","shell.execute_reply":"2024-06-15T14:59:09.536520Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Train Accuracy: 99.82%\n","output_type":"stream"}]},{"cell_type":"code","source":"%pip install torchprofile torchsummary","metadata":{"execution":{"iopub.status.busy":"2024-06-15T15:16:34.501768Z","iopub.execute_input":"2024-06-15T15:16:34.502119Z","iopub.status.idle":"2024-06-15T15:16:46.997815Z","shell.execute_reply.started":"2024-06-15T15:16:34.502093Z","shell.execute_reply":"2024-06-15T15:16:46.996553Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Collecting torchprofile\n  Downloading torchprofile-0.0.4-py3-none-any.whl.metadata (303 bytes)\nRequirement already satisfied: numpy>=1.14 in /opt/conda/lib/python3.10/site-packages (from torchprofile) (1.26.4)\nRequirement already satisfied: torch>=1.4 in /opt/conda/lib/python3.10/site-packages (from torchprofile) (2.1.2)\nRequirement already satisfied: torchvision>=0.4 in /opt/conda/lib/python3.10/site-packages (from torchprofile) (0.16.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.4->torchprofile) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.4->torchprofile) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.4->torchprofile) (1.12.1)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.4->torchprofile) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4->torchprofile) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.4->torchprofile) (2024.3.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision>=0.4->torchprofile) (2.32.3)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision>=0.4->torchprofile) (9.5.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.4->torchprofile) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.4->torchprofile) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.4->torchprofile) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.4->torchprofile) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.4->torchprofile) (2024.2.2)\nRequirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.4->torchprofile) (1.3.0)\nDownloading torchprofile-0.0.4-py3-none-any.whl (7.7 kB)\nInstalling collected packages: torchprofile\nSuccessfully installed torchprofile-0.0.4\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"from torchsummary import summary\nimport torchvision.models as models\nfrom torchprofile import profile_macs\n# Calculate the number of trainable parameters and all parameters\ntrainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\nall_params = sum(p.numel() for p in model.parameters())\n\nprint('trainable_params = ', trainable_params)\nprint('all_params = ', all_params)\n\n# Create a dummy input tensor with the same size as the input images\ninput_tensor = torch.randn(1, 3, 224, 224).to(device)\n\n# Calculate FLOPs\nflops = profile_macs(model, input_tensor)\nprint(f'FLOPs: {flops / 1e9:.2f} GFLOPs')  # Convert to GFLOPs (GigaFLOPs)","metadata":{"execution":{"iopub.status.busy":"2024-06-15T15:16:57.199766Z","iopub.execute_input":"2024-06-15T15:16:57.200186Z","iopub.status.idle":"2024-06-15T15:16:57.779358Z","shell.execute_reply.started":"2024-06-15T15:16:57.200148Z","shell.execute_reply":"2024-06-15T15:16:57.778513Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"trainable_params =  4010110\nall_params =  4010110\nFLOPs: 0.39 GFLOPs\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::silu_\". Skipped.\n  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n","output_type":"stream"}]},{"cell_type":"code","source":"torch.save(model, '/kaggle/working/2024_06_15_trial.pt')","metadata":{"execution":{"iopub.status.busy":"2024-06-16T03:38:21.316533Z","iopub.execute_input":"2024-06-16T03:38:21.317831Z","iopub.status.idle":"2024-06-16T03:38:21.409414Z","shell.execute_reply.started":"2024-06-16T03:38:21.317787Z","shell.execute_reply":"2024-06-16T03:38:21.408635Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"#print(\"Model Layers:\")\n#omodel = models.efficientnet_b0(pretrained=True)\nfor layer in model.children():\n    print(layer)","metadata":{"execution":{"iopub.status.busy":"2024-06-15T15:41:44.362661Z","iopub.execute_input":"2024-06-15T15:41:44.363574Z","iopub.status.idle":"2024-06-15T15:41:44.371954Z","shell.execute_reply.started":"2024-06-15T15:41:44.363541Z","shell.execute_reply":"2024-06-15T15:41:44.371136Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Sequential(\n  (0): Conv2dNormActivation(\n    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): SiLU(inplace=True)\n  )\n  (1): Sequential(\n    (0): MBConv(\n      (block): Sequential(\n        (0): Conv2dNormActivation(\n          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): SiLU(inplace=True)\n        )\n        (1): SqueezeExcitation(\n          (avgpool): AdaptiveAvgPool2d(output_size=1)\n          (fc1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n          (fc2): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n          (activation): SiLU(inplace=True)\n          (scale_activation): Sigmoid()\n        )\n        (2): Conv2dNormActivation(\n          (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n    )\n  )\n  (2): Sequential(\n    (0): MBConv(\n      (block): Sequential(\n        (0): Conv2dNormActivation(\n          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): SiLU(inplace=True)\n        )\n        (1): Conv2dNormActivation(\n          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): SiLU(inplace=True)\n        )\n        (2): SqueezeExcitation(\n          (avgpool): AdaptiveAvgPool2d(output_size=1)\n          (fc1): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n          (fc2): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n          (activation): SiLU(inplace=True)\n          (scale_activation): Sigmoid()\n        )\n        (3): Conv2dNormActivation(\n          (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (stochastic_depth): StochasticDepth(p=0.0125, mode=row)\n    )\n    (1): MBConv(\n      (block): Sequential(\n        (0): Conv2dNormActivation(\n          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): SiLU(inplace=True)\n        )\n        (1): Conv2dNormActivation(\n          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): SiLU(inplace=True)\n        )\n        (2): SqueezeExcitation(\n          (avgpool): AdaptiveAvgPool2d(output_size=1)\n          (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n          (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n          (activation): SiLU(inplace=True)\n          (scale_activation): Sigmoid()\n        )\n        (3): Conv2dNormActivation(\n          (0): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (stochastic_depth): StochasticDepth(p=0.025, mode=row)\n    )\n  )\n  (3): Sequential(\n    (0): MBConv(\n      (block): Sequential(\n        (0): Conv2dNormActivation(\n          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): SiLU(inplace=True)\n        )\n        (1): Conv2dNormActivation(\n          (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): SiLU(inplace=True)\n        )\n        (2): SqueezeExcitation(\n          (avgpool): AdaptiveAvgPool2d(output_size=1)\n          (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n          (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n          (activation): SiLU(inplace=True)\n          (scale_activation): Sigmoid()\n        )\n        (3): Conv2dNormActivation(\n          (0): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (stochastic_depth): StochasticDepth(p=0.037500000000000006, mode=row)\n    )\n    (1): MBConv(\n      (block): Sequential(\n        (0): Conv2dNormActivation(\n          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): SiLU(inplace=True)\n        )\n        (1): Conv2dNormActivation(\n          (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n          (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): SiLU(inplace=True)\n        )\n        (2): SqueezeExcitation(\n          (avgpool): AdaptiveAvgPool2d(output_size=1)\n          (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n          (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n          (activation): SiLU(inplace=True)\n          (scale_activation): Sigmoid()\n        )\n        (3): Conv2dNormActivation(\n          (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (stochastic_depth): StochasticDepth(p=0.05, mode=row)\n    )\n  )\n  (4): Sequential(\n    (0): MBConv(\n      (block): Sequential(\n        (0): Conv2dNormActivation(\n          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): SiLU(inplace=True)\n        )\n        (1): Conv2dNormActivation(\n          (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n          (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): SiLU(inplace=True)\n        )\n        (2): SqueezeExcitation(\n          (avgpool): AdaptiveAvgPool2d(output_size=1)\n          (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n          (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n          (activation): SiLU(inplace=True)\n          (scale_activation): Sigmoid()\n        )\n        (3): Conv2dNormActivation(\n          (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (stochastic_depth): StochasticDepth(p=0.0625, mode=row)\n    )\n    (1): MBConv(\n      (block): Sequential(\n        (0): Conv2dNormActivation(\n          (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): SiLU(inplace=True)\n        )\n        (1): Conv2dNormActivation(\n          (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n          (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): SiLU(inplace=True)\n        )\n        (2): SqueezeExcitation(\n          (avgpool): AdaptiveAvgPool2d(output_size=1)\n          (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n          (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n          (activation): SiLU(inplace=True)\n          (scale_activation): Sigmoid()\n        )\n        (3): Conv2dNormActivation(\n          (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (stochastic_depth): StochasticDepth(p=0.07500000000000001, mode=row)\n    )\n    (2): MBConv(\n      (block): Sequential(\n        (0): Conv2dNormActivation(\n          (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): SiLU(inplace=True)\n        )\n        (1): Conv2dNormActivation(\n          (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n          (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): SiLU(inplace=True)\n        )\n        (2): SqueezeExcitation(\n          (avgpool): AdaptiveAvgPool2d(output_size=1)\n          (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n          (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n          (activation): SiLU(inplace=True)\n          (scale_activation): Sigmoid()\n        )\n        (3): Conv2dNormActivation(\n          (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (stochastic_depth): StochasticDepth(p=0.08750000000000001, mode=row)\n    )\n  )\n  (5): Sequential(\n    (0): MBConv(\n      (block): Sequential(\n        (0): Conv2dNormActivation(\n          (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): SiLU(inplace=True)\n        )\n        (1): Conv2dNormActivation(\n          (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n          (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): SiLU(inplace=True)\n        )\n        (2): SqueezeExcitation(\n          (avgpool): AdaptiveAvgPool2d(output_size=1)\n          (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n          (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n          (activation): SiLU(inplace=True)\n          (scale_activation): Sigmoid()\n        )\n        (3): Conv2dNormActivation(\n          (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n    )\n    (1): MBConv(\n      (block): Sequential(\n        (0): Conv2dNormActivation(\n          (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): SiLU(inplace=True)\n        )\n        (1): Conv2dNormActivation(\n          (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n          (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): SiLU(inplace=True)\n        )\n        (2): SqueezeExcitation(\n          (avgpool): AdaptiveAvgPool2d(output_size=1)\n          (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n          (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n          (activation): SiLU(inplace=True)\n          (scale_activation): Sigmoid()\n        )\n        (3): Conv2dNormActivation(\n          (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (stochastic_depth): StochasticDepth(p=0.1125, mode=row)\n    )\n    (2): MBConv(\n      (block): Sequential(\n        (0): Conv2dNormActivation(\n          (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): SiLU(inplace=True)\n        )\n        (1): Conv2dNormActivation(\n          (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n          (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): SiLU(inplace=True)\n        )\n        (2): SqueezeExcitation(\n          (avgpool): AdaptiveAvgPool2d(output_size=1)\n          (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n          (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n          (activation): SiLU(inplace=True)\n          (scale_activation): Sigmoid()\n        )\n        (3): Conv2dNormActivation(\n          (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (stochastic_depth): StochasticDepth(p=0.125, mode=row)\n    )\n  )\n  (6): Sequential(\n    (0): MBConv(\n      (block): Sequential(\n        (0): Conv2dNormActivation(\n          (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): SiLU(inplace=True)\n        )\n        (1): Conv2dNormActivation(\n          (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n          (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): SiLU(inplace=True)\n        )\n        (2): SqueezeExcitation(\n          (avgpool): AdaptiveAvgPool2d(output_size=1)\n          (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n          (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n          (activation): SiLU(inplace=True)\n          (scale_activation): Sigmoid()\n        )\n        (3): Conv2dNormActivation(\n          (0): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (stochastic_depth): StochasticDepth(p=0.1375, mode=row)\n    )\n    (1): MBConv(\n      (block): Sequential(\n        (0): Conv2dNormActivation(\n          (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): SiLU(inplace=True)\n        )\n        (1): Conv2dNormActivation(\n          (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n          (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): SiLU(inplace=True)\n        )\n        (2): SqueezeExcitation(\n          (avgpool): AdaptiveAvgPool2d(output_size=1)\n          (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n          (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n          (activation): SiLU(inplace=True)\n          (scale_activation): Sigmoid()\n        )\n        (3): Conv2dNormActivation(\n          (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (stochastic_depth): StochasticDepth(p=0.15000000000000002, mode=row)\n    )\n    (2): MBConv(\n      (block): Sequential(\n        (0): Conv2dNormActivation(\n          (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): SiLU(inplace=True)\n        )\n        (1): Conv2dNormActivation(\n          (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n          (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): SiLU(inplace=True)\n        )\n        (2): SqueezeExcitation(\n          (avgpool): AdaptiveAvgPool2d(output_size=1)\n          (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n          (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n          (activation): SiLU(inplace=True)\n          (scale_activation): Sigmoid()\n        )\n        (3): Conv2dNormActivation(\n          (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (stochastic_depth): StochasticDepth(p=0.1625, mode=row)\n    )\n    (3): MBConv(\n      (block): Sequential(\n        (0): Conv2dNormActivation(\n          (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): SiLU(inplace=True)\n        )\n        (1): Conv2dNormActivation(\n          (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n          (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): SiLU(inplace=True)\n        )\n        (2): SqueezeExcitation(\n          (avgpool): AdaptiveAvgPool2d(output_size=1)\n          (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n          (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n          (activation): SiLU(inplace=True)\n          (scale_activation): Sigmoid()\n        )\n        (3): Conv2dNormActivation(\n          (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (stochastic_depth): StochasticDepth(p=0.17500000000000002, mode=row)\n    )\n  )\n  (7): Sequential(\n    (0): MBConv(\n      (block): Sequential(\n        (0): Conv2dNormActivation(\n          (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): SiLU(inplace=True)\n        )\n        (1): Conv2dNormActivation(\n          (0): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n          (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): SiLU(inplace=True)\n        )\n        (2): SqueezeExcitation(\n          (avgpool): AdaptiveAvgPool2d(output_size=1)\n          (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n          (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n          (activation): SiLU(inplace=True)\n          (scale_activation): Sigmoid()\n        )\n        (3): Conv2dNormActivation(\n          (0): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (stochastic_depth): StochasticDepth(p=0.1875, mode=row)\n    )\n  )\n  (8): Conv2dNormActivation(\n    (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): SiLU(inplace=True)\n  )\n)\nAdaptiveAvgPool2d(output_size=1)\nSequential(\n  (0): Dropout(p=0.2, inplace=True)\n  (1): Linear(in_features=1280, out_features=2, bias=True)\n)\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}